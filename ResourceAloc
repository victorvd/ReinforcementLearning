from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
import gymnasium as gym
from gymnasium import spaces
import numpy as np

class ComplexSatelliteResourceAllocationEnv(gym.Env):
    def __init__(self, num_satellites, max_power, max_computing_capacity, max_bandwidth, render_mode=None):
        super().__init__()
        self.render_mode = render_mode
        self.metadata = {"render_modes": ["human", "rgb_array"]}

        self.num_satellites = num_satellites
        self.max_power = max_power
        self.max_computing_capacity = max_computing_capacity
        self.max_bandwidth = max_bandwidth

        # Action space: allocate resources for each satellite (power, computing, bandwidth)
        self.action_space = spaces.Box(low=np.zeros((num_satellites * 3)), high=np.ones((num_satellites * 3)), dtype=np.float32)

        # Observation space: current usage for each satellite (power, computing, bandwidth)
        self.observation_space = spaces.Box(low=np.zeros((num_satellites * 3)),
                                             high=np.array([max_power] * num_satellites +
                                                           [max_computing_capacity] * num_satellites +
                                                           [max_bandwidth] * num_satellites),
                                             dtype=np.float32)

        self.state = None
        self.step_counter = 0

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.state = np.zeros((self.num_satellites * 3), dtype=np.float32)  # Reset to zero usage
        self.step_counter = 0
        return self.state, {}  # Return state and empty info dict

    def step(self, action):
        action = np.array(action).flatten()  # Flatten action array

        # Calculate resource usage for each satellite
        power_usage = action[:self.num_satellites] * self.max_power
        computing_usage = action[self.num_satellites:self.num_satellites*2] * self.max_computing_capacity
        bandwidth_usage = action[self.num_satellites*2:] * self.max_bandwidth

        # Calculate rewards based on resource usage
        reward = 0
        for i in range(self.num_satellites):
            if power_usage[i] > self.max_power or computing_usage[i] > self.max_computing_capacity or bandwidth_usage[i] > self.max_bandwidth:
                reward -= 10  # Penalty for exceeding limits
            else:
                reward += (self.max_power - power_usage[i]) + (self.max_computing_capacity - computing_usage[i]) + (self.max_bandwidth - bandwidth_usage[i])

        # Update state with current usage
        self.state = np.concatenate((power_usage, computing_usage, bandwidth_usage))

        done = np.all(self.state >= [self.max_power] * self.num_satellites +
                      [self.max_computing_capacity] * self.num_satellites +
                      [self.max_bandwidth] * self.num_satellites)

        truncated = self.step_counter >= 100

        self.step_counter += 1

        return self.state, reward, done, truncated, {}

    def render(self):
        if self.render_mode == "human":
            print(f"State: {self.state}")
            for i in range(self.num_satellites):
                print(f"Satellite {i}: Power usage = {self.state[i]:.2f}, Computing usage = {self.state[self.num_satellites + i]:.2f}, Bandwidth usage = {self.state[2*self.num_satellites + i]:.2f}")

# Environment setup
num_satellites = 3
max_power = 100
max_computing_capacity = 100
max_bandwidth = 50

env = ComplexSatelliteResourceAllocationEnv(num_satellites, max_power, max_computing_capacity, max_bandwidth, render_mode="human")
env = DummyVecEnv([lambda: env])

# Train the PPO agent
model = PPO("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=10000)

# Test the model
obs = env.reset()
for _ in range(10):
    action, _states = model.predict(obs)
    obs, reward, done, info = env.step(action)
    env.render()

    if isinstance(done, bool) and done:
        print("Episode finished!")
        break
